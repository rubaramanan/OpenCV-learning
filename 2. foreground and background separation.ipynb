{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo\n",
    "\n",
    "Now we go for grabcut algorithm with OpenCV. OpenCV has the function, cv.grabCut() for this. We will see its arguments first:\n",
    "\n",
    "    img - Input image\n",
    "    mask - It is a mask image where we specify which areas are background, foreground or probable background/foreground etc. It is done by the following flags, cv.GC_BGD, cv.GC_FGD, cv.GC_PR_BGD, cv.GC_PR_FGD, or simply pass 0,1,2,3 to image.\n",
    "    rect - It is the coordinates of a rectangle which includes the foreground object in the format (x,y,w,h)\n",
    "    bdgModel, fgdModel - These are arrays used by the algorithm internally. You just create two np.float64 type zero arrays of size (1,65).\n",
    "    iterCount - Number of iterations the algorithm should run.\n",
    "    mode - It should be cv.GC_INIT_WITH_RECT or cv.GC_INIT_WITH_MASK or combined which decides whether we are drawing rectangle or final touchup strokes.\n",
    "\n",
    "First let's see with rectangular mode. We load the image, create a similar mask image. We create fgdModel and bgdModel. We give the rectangle parameters. It's all straight-forward. Let the algorithm run for 5 iterations. Mode should be cv.GC_INIT_WITH_RECT since we are using rectangle. Then run the grabcut. It modifies the mask image. In the new mask image, pixels will be marked with four flags denoting background/foreground as specified above. So we modify the mask such that all 0-pixels and 2-pixels are put to 0 (ie background) and all 1-pixels and 3-pixels are put to 1(ie foreground pixels). Now our final mask is ready. Just multiply it with input image to get the segmented image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'IMREAD_RGB'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\OpenCV learning\\2. foreground and background separation.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/OpenCV%20learning/2.%20foreground%20and%20background%20separation.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m original \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39m'\u001b[39m\u001b[39mcat.jpg\u001b[39m\u001b[39m'\u001b[39m, cv2\u001b[39m.\u001b[39;49mIMREAD_RGB)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OpenCV%20learning/2.%20foreground%20and%20background%20separation.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m img \u001b[39m=\u001b[39m original\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OpenCV%20learning/2.%20foreground%20and%20background%20separation.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(img\u001b[39m.\u001b[39mshape[:\u001b[39m2\u001b[39m], np\u001b[39m.\u001b[39muint8)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'IMREAD_RGB'"
     ]
    }
   ],
   "source": [
    "original = cv2.imread('cat.jpg', cv2.IMREAD_RGB)\n",
    "img = original.copy()\n",
    "\n",
    "mask = np.zeros(img.shape[:2], np.uint8)\n",
    "\n",
    "bgdModel = np.zeros((1,65), np.float64)\n",
    "fgdModel = np.zeros((1,65), np.float64)\n",
    "\n",
    "rect = (50,40,450,590)\n",
    "\n",
    "iter_count = 5\n",
    "\n",
    "cv2.grabCut(img, mask, rect, bgdModel, fgdModel, iter_count, cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
    "img = img*mask2[:,:,np.newaxis]\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "plt.title('GrabCut')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(original)\n",
    "plt.title('Origina')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\grabcut.cpp:386: error: (-215:Assertion failed) !bgdSamples.empty() && !fgdSamples.empty() in function 'initGMMs'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32md:\\OpenCV learning\\2. foreground and background separation.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OpenCV%20learning/2.%20foreground%20and%20background%20separation.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m fgdModel \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39m1\u001b[39m,\u001b[39m65\u001b[39m), np\u001b[39m.\u001b[39mfloat64)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OpenCV%20learning/2.%20foreground%20and%20background%20separation.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m iter_count \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/OpenCV%20learning/2.%20foreground%20and%20background%20separation.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m mask, bgdModel, fgdModel \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mgrabCut(img, mask, \u001b[39mNone\u001b[39;49;00m, bgdModel, fgdModel, iter_count, cv2\u001b[39m.\u001b[39;49mGC_INIT_WITH_MASK)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OpenCV%20learning/2.%20foreground%20and%20background%20separation.ipynb#W5sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere((mask\u001b[39m==\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m|\u001b[39m(mask\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m),\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39muint8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OpenCV%20learning/2.%20foreground%20and%20background%20separation.ipynb#W5sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m*\u001b[39mmask[:,:,np\u001b[39m.\u001b[39mnewaxis]\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\grabcut.cpp:386: error: (-215:Assertion failed) !bgdSamples.empty() && !fgdSamples.empty() in function 'initGMMs'\n"
     ]
    }
   ],
   "source": [
    "newmask = cv2.imread('cat.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "mask = np.zeros(img.shape[:2], np.uint8)\n",
    "\n",
    "mask[newmask == 0] = 0\n",
    "mask[newmask == 255] = 1\n",
    "\n",
    "bgdModel = np.zeros((1,65), np.float64)\n",
    "fgdModel = np.zeros((1,65), np.float64)\n",
    "\n",
    "\n",
    "iter_count = 5\n",
    "\n",
    "mask, bgdModel, fgdModel = cv2.grabCut(img, mask, None, bgdModel, fgdModel, iter_count, cv2.GC_INIT_WITH_MASK)\n",
    "\n",
    "mask = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
    "img = img*mask[:,:,np.newaxis]\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "plt.title('Grabcut')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(original)\n",
    "plt.title('Original')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
